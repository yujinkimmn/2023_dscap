import streamlit as st
import altair as alt
import pandas as pd
import time
import re
from datetime import datetime, date
import folium
from folium.plugins import HeatMap, MarkerCluster
from streamlit_folium import st_folium
from streamlit_modal import Modal
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.font_manager import fontManager, FontProperties
import numpy as np
from gensim.models import Word2Vec
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from wordcloud import WordCloud


fp1 = "EDA/Region_analysis/ì§€ì—­ë³„ë§ˆì•½ë¥˜ë¹ˆë„_ìœ„ê²½ë„í¬í•¨_ìµœì¢….csv"
fp2 = "twitterdata/labeling/total_labeling_preprocessed.csv"
fp3 = "twitterdata/preprocessing/preprocessed/total_preprocessed_name_revise.csv"  #ì´ë¦„ íŠ¹ìˆ˜ê¸°í˜¸ ì²˜ë¦¬
fp4 = "Prototype/files/NanumBarunGothic.ttf"  #í°íŠ¸ ê²½ë¡œ

file_timeseries = "Prototype/files/total_preprocessed.csv"

file_clustering = "Prototype/files/total_tokenized_mecab.csv"

@st.cache_data
def load_data(file_path):
    data = pd.read_csv(file_path, encoding = "utf-8")
    return data

def get_timechart(data):
    hover = alt.selection_single(
        fields=["date"],
        nearest=True,
        on="mouseover",
        empty="none",
    )
    
    
    lines = (
        alt.Chart(data, height=500, title="ë§ˆì•½ ê±°ë˜ ê²Œì‹œë¬¼ ì¶”ì´")
        .mark_bar()
        .encode(
            x="date",
            y="count",
            color=alt.Color("count"),
        )
    )
    
    points = lines.transform_filter(hover).mark_circle(color="red", size=300)

    tooltips = (
        alt.Chart(data)
        .mark_rule()
        .encode(
            x="date",
            y="count",
            opacity=alt.condition(hover, alt.value(0.3), alt.value(0)),
            tooltip=[
                alt.Tooltip("date", title="Date"),
                alt.Tooltip("count", title="Count"),
            ],
        )
        .add_selection(hover)
    )

    return (lines + points + tooltips).interactive()
    
def timeseries(file_path):
    global df
    df = load_data(file_path)
    global flowday
    
    df['year'] = 0
    df['month'] = 0
    df['day'] = 0

    for i in range(len(df['date'])):
      if (str(df['date'][i])[4] == '.') :
        df['year'][i] = str(df['date'][i]).split(".")[0]
        df['month'][i] = str(df['date'][i]).split(".")[1]
        df['day'][i] = (str(df['date'][i]).split(".")[2]).split(" ")[0]
      else:
        df['year'][i] = str(df['date'][i]).split("-")[0]
        df['month'][i] = str(df['date'][i]).split("-")[1]
        df['day'][i] = (str(df['date'][i]).split("-")[2]).split(" ")[0]

    flowday = df.groupby(['year', 'month', 'day']).count().reset_index()
    flowday = flowday.iloc[0:, :4]
    flowday['date'] = 0
    
    for i in range(len(flowday)):
        flowday['date'][i] = str(flowday['year'][i]) + "-" + str(flowday['month'][i]) + "-" + str(flowday['day'][i])

    flowday = flowday.sort_values("date")
    flowday['date'] = pd.to_datetime(flowday['date'])
    flowday = flowday.iloc[0:, 3:5]
    flowday = flowday.rename(columns={'type1':'count'})
    flowday = flowday.groupby(['date']).sum()
    flowday = flowday.reset_index()

    print(flowday)
    # ê¸°ë³¸ line chart í˜•íƒœ
    #st.line_chart(flowday, x="date", y="count")
    
    if ((2021 <= int(str(time[0]).split(" ")[0].split("-")[0]) <= 2022) or (int(str(time[0]).split(" ")[0].split("-")[0]) == 2023 & int(str(time[0]).split(" ")[0].split("-")[1]) <= 3)) & ((2021 <= int(str(time[1]).split(" ")[0].split("-")[0]) <= 2022) or (int(str(time[1]).split(" ")[0].split("-")[0]) == 2023 & int(str(time[1]).split(" ")[0].split("-")[1]) <= 3)):
            flowday_selected = flowday
            a = flowday_selected[str(time[0]).split(" ")[0] <= flowday_selected['date']]
            b = a[a['date'] <= str(time[1]).split(" ")[0]]
            b = pd.DataFrame(b)
            b = b.reset_index()
            b = b.iloc[0:, 1:3]
            print(b)
            chart = get_timechart(b)
    else:
        chart = get_timechart(flowday)
    
    ANNOTATIONS = [
    ("2021-11-03", "ì¼ 5ê°œ ì´ë‚´ ìœ ì§€"),
    ("2022-08-19", "ë§ˆì•½ ê±°ë˜ ê²Œì‹œë¬¼ ì¦ê°€ ì¶”ì„¸"),
    ("2022-12-25", "ë§ˆì•½ ê±°ë˜ ê²Œì‹œë¬¼ ê°ì†Œ ì¶”ì„¸"),
    ("2022-10-28", "ë§ˆì•½ ê±°ë˜ ê²Œì‹œë¬¼ ê¸‰ì¦"),
    ("2023-03-28", "ì¼ 1000ê°œ ëŒíŒŒ"),]
    
    annotations_df = pd.DataFrame(ANNOTATIONS, columns=["date", "event"])
    annotations_df.date = pd.to_datetime(annotations_df.date)
    annotations_df["y"] = 10
    
    annotation_layer = (
    alt.Chart(annotations_df)
    .mark_text(size=20, text="â¬‡", dx=-8, dy=-10, align="left")
    .encode(
        x="date:T",
        y=alt.Y("y:Q"),
        tooltip=["event"],
    )
    .interactive())

    st.altair_chart((chart + annotation_layer), use_container_width=True)
    
@st.cache_data
def load_data(file_path):
    data = pd.read_csv(file_path)
    return data
    

def visualize_clusters(df, n_clusters):
    graph = alt.Chart(df.reset_index()).mark_point(filled=True, size=60).encode(
        x=alt.X('x_values'),
        y=alt.Y('y_values'),
        color=alt.Color('labels'),
        tooltip=['word', 'labels']
    ).interactive()
    st.altair_chart(graph, use_container_width=True)
    

def clustering(file_path):
    global df
    df = load_data(file_path)
    
    print(df)
    
    for i in range(len(df['mecab'])):
        df['mecab'].loc[i] = eval(df['mecab'].loc[i])
        
    total = []
    for idx in range(len(df['mecab'])):
      word = []
      for i, j in df['mecab'].loc[idx]:
        if j == "NNP" or j == "SL" or j == "NNG":
          word.append(i)
      total.append(word)
    
    df = df.assign(word = total)
    
    corpus = []
    for i in df['word']:
      corpus.append(i)

    corpus_total = []
    for i in df['word']:
      for j in i:
        corpus_total.append(j)
    
    model = Word2Vec(corpus, vector_size=100, window = 4, min_count = 1, workers = 4, sg = 1)
    
    model_result = model.wv.most_similar('ì‘ëŒ€ê¸°')
    print(model_result)

    # fit a 2d PCA model to the vectors

    vectors = model.wv.vectors
    words = list(model.wv.key_to_index.keys())
    pca = PCA(n_components=2)
    PCA_result = pca.fit_transform(vectors)

    # prepare a dataframe
    words = pd.DataFrame(words)
    PCA_result = pd.DataFrame(PCA_result)
    PCA_result['x_values'] =PCA_result.iloc[0:, 0]
    PCA_result['y_values'] =PCA_result.iloc[0:, 1]
    PCA_final = pd.merge(words, PCA_result, left_index=True, right_index=True)
    PCA_final['word'] =PCA_final.iloc[0:, 0]
    PCA_data_complet =PCA_final[['word','x_values','y_values']]

    kmeans = KMeans(n_clusters=5)
    kmeans.fit(PCA_result.iloc[0:,:2])
    PCA_data_complet['labels'] = kmeans.predict(PCA_result.iloc[0:,:2])
    
    # ë‹¨ì–´ ë¹ˆë„ ìˆ˜ ì—´ ì¶”ê°€
    PCA_data_complet['counts'] = 0
    for i, word in enumerate(PCA_data_complet['word']):
      PCA_data_complet['counts'][i] = corpus_total.count(word)
    
    global PCA_drug
    PCA_drug = PCA_data_complet[PCA_data_complet['labels']==PCA_data_complet.loc[0].labels]
    
    kmeans = KMeans(n_clusters=2)
    kmeans.fit(PCA_drug.iloc[0:,1:3])
    PCA_drug['labels'] = kmeans.predict(PCA_drug.iloc[0:,1:3])
    
    print(PCA_drug)
    
    visualize_clusters(PCA_drug, 2)


def w_cloud():
    PCA_drug_removed = PCA_drug

    keywords = ['ìŠ¤í‹¸ë…¹ìŠ¤', 'ì‹ ì˜ëˆˆë¬¼', 'ì—í† ë¯¸ë°ì´íŠ¸', 'ì˜¥ì‹œì½”ëˆ', 'ì¡¸í”¼ë€', 'íŠ¸ë¼ë§ˆëŒ', 'ìº”ë””ì¼€ì´', 'ì¼€íƒ€ë¯¼',
                'ëŸ¬ì‰¬íŒŒí¼', 'ëìŠˆ', 'ì •ê¸€ì£¼ìŠ¤', 'ì—˜ì—ìŠ¤ë””', 'ì—‘ìŠ¤í„°ì‹œ', 'ë§ˆë²•ì˜ë²„ì„¯', 'í™˜ê°ë²„ì„¯', 
                'ë–¨ì•¡', 'ë¶í•œì‚°ì•„ì´ìŠ¤', 'ë¹™ë‘', 'ì‚¥ë‘', 'ì‚¬ë¼', 'ìƒ¤ë¶€', 'ì‹œì›í•œìˆ ', 'ì•„ì´ìŠ¤ìˆ ', 'ì•¡ìƒë–¨', 'ì‘ëŒ€ê¸°',
                'íˆë¡œë½•', 'í¬ë¦¬ìŠ¤íƒˆ', 'ì°¨ê°€ìš´ìˆ ', 'ì•„ì´ìŠ¤', 'ì°¬ìˆ ', 'ë“œë¼í¼', 'ë¸Œì•¡', 'ì•„ì´ìŠ¤ë“œë', 'í´ëŸ½ì•½', 
                'í…”ë ˆ', 'íŒŒí‹°ì•½', 'íŒ¨ì¹˜', 'í›„ë¦¬ë² ì´ìŠ¤', 'ì£¼ì‚¬ê¸°', 'í—ˆë¸Œ', 'ë¬¼ë½•', 'ë°œì •ì œ', 'ìµœìŒì œ', 'ì‚¬í‹°ë°”',
                'ì¸ë””ì¹´', 'í•©ì„±ëŒ€ë§ˆ', 'í•´ì‹œì‹œ', 'ëŒ€ë§ˆì´ˆ', 'ëŒ€ë§ˆ', 'ìº”ë””', 'ì¼€ì´','í´ëŸ½', 'íŒŒí‹°', 'ë„ë¦¬ë„ë¦¬', 'ì½”ì¹´ì¸', 'ë² ì´ìŠ¤', 'ëª°ë¦¬']

    for i in keywords:
        PCA_drug_removed = PCA_drug_removed[~PCA_drug_removed['word'].str.contains(i)]  #í‚¤ì›Œë“œ ì œì™¸í•œ ê²°ê³¼

    words_rev = []
    counts_rev = []
    words_list_rev = list(PCA_drug_removed['word'])
    counts_list_rev = list(PCA_drug_removed['counts'])

    for i in range(len(words_list_rev)):
        if len(words_list_rev[i]) >= 2:  #2ê¸€ì ì´ìƒì¸ ë‹¨ì–´ë§Œ
            words_rev.append(words_list_rev[i])
            counts_rev.append(counts_list_rev[i])
    word_count_removed = dict(zip(words_rev, counts_rev))    

    #ì›Œë“œí´ë¼ìš°ë“œ ê·¸ë¦¬ê¸°
    global fp4
    wordcloud = WordCloud(font_path = fp4, background_color = 'white', colormap = 'rainbow_r',
                     width = 4000, height = 3000).generate_from_frequencies(word_count_removed)
    fig = plt.figure()
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.show()
    st.pyplot(fig)   


def histogram():
    global fp3
    df = pd.read_csv(fp3)

    df.drop_duplicates(['content', 'user.username', 'date'], inplace=True)  #ì¤‘ë³µìœ¼ë¡œ ìˆ˜ì§‘ëœ íŠ¸ìœ— ì œê±°
    df_grouped = pd.DataFrame(df.groupby('user.displayname')['content'].count())  #ë‹‰ë„¤ì„ ê¸°ì¤€ìœ¼ë¡œ ê°œìˆ˜ ì„¸ê¸°
    df_grouped.reset_index(inplace = True)
    df_grouped.sort_values('content', inplace=True, ascending=False)
    df_new = df_grouped[df_grouped['content'] >= 20]  #20ë²ˆ ì´ìƒ ë“±ì¥í•œ ë‹‰ë„¤ì„

    #íˆìŠ¤í† ê·¸ë¨
    global fp4
    fontManager.addfont(fp4)
    prop = FontProperties(fname = fp4)
    plt.figure(figsize = (20,15))
    sns.set(font = prop.get_name(), font_scale = 1.5, rc = {'axes.unicode_minus': False}, style = 'darkgrid')
    fig = sns.barplot(
        x = 'content', y = 'user.displayname', data = df_new, width = 0.8)
    fig.set_yticks(np.arange(0, len(df_new)+1, 2))
    fig.set_title('User Name Appeared More Than 20 Times', fontsize = 20)
    fig.set_xlabel('Frequency', size = 15)
    fig.set_ylabel('Name', size = 15)
    fig = fig.figure
    st.pyplot(fig)

    
def popup_html():
    html = '''<!DOCTYPE html>
<html>
<head>
  <title>Twitter Design</title>
  <style>
    /* CSS styles */
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
    }
    
    .tweet {
      margin-bottom: 20px;
      border: 1px solid #ccc;
      padding: 10px;
      background-color: #f9f9f9;
    }
    
    .username {
      font-weight: bold;
      color: #1da1f2;
    }
    
    .content {
      margin-top: 5px;
    }
    
    .userid {
      font-size: 0.8em;
      color: #777;
    }
    /* Custom modal size */
    .custom-modal {
        max-width: 800px;
        height: 400px;
        overflow-y: scroll;
        scrollbar-width: thin;
    }
  </style>
</head>
<body>
  <div class="tweet">
    <div class="username">JohnDoe</div>
    <div class="userid">@johndoe123</div>
    <div class="content">
      Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis gravida lobortis aliquet.
    </div>
  </div>
  
  <div class="tweet">
    <div class="username">JaneSmith</div>
    <div class="userid">@janesmith456</div>
    <div class="content">
      Nulla nec ex vitae nisi feugiat rhoncus id non neque.
    </div>
  </div>
</body>
</html>
'''

    return html


def map_visualization():
    global fp1
    data = load_data(fp1)

    location = [[lat, lng] for lat, lng, region in zip(data['ìœ„ë„'], data['ê²½ë„'], data['ì§€ì—­ëª…']) if region == region_option]
    lat = location[0][0]
    lng = location[0][1]
    zoom = 9
    if region_option == "ì„œìš¸íŠ¹ë³„ì‹œ":
        zoom = 12

    m = folium.Map(location=[lat, lng], zoom_start=zoom, tiles='OpenStreetMap')
    # Convert data to proper types
    lats = data['ìœ„ë„'].values.astype(float)
    lngs = data['ê²½ë„'].values.astype(float)
    freqs = data['ë¹ˆë„'].values.astype(float)
    # Create a HeatMap layer
    heat_data = [[lat, lng, freq] for lat, lng, freq in zip(lats, lngs, freqs)]
    HeatMap(heat_data).add_to(m)

    # Create a MarkerCluster layer
    marker_cluster = MarkerCluster().add_to(m)

    # Add markers to the MarkerCluster layer
    for index, row in data.iterrows():
        lat = row['ìœ„ë„']
        lng = row['ê²½ë„']
        freq = row['ë¹ˆë„']
        drug = row['ë§ˆì•½ë¥˜']
        popup_content = folium.Popup(f'ë¹ˆë„: {freq}, ë§ˆì•½ë¥˜: {drug}', max_width=300)

        # Create a marker and add it to the MarkerCluster layer
        marker = folium.Marker(location=[lat, lng], popup=popup_content, tooltip='ë§ˆì•½ë¥˜ í™•ì¸')
        marker.add_to(marker_cluster)

    st_data = st_folium(m, width=725)


# Set up the layout
st.set_page_config(page_title="Dashboard", page_icon="ğŸ“Š", 
                   layout='wide', initial_sidebar_state='expanded')

with st.sidebar:
    with st.spinner("Loading..."):
        time.sleep(0.5)
    
    st.subheader("Parameter")
    # í•´ë‹¹ ê¸°ê°„ì˜ ì‹œê³„ì—´ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ì‹¶ì—ˆìŒ! ë¹¼ë„ ìƒê´€ì—†ì–´ìœ ~
    # ì˜¤ëŠ˜ ë‚ ì§œë¡œ ìŠ¬ë¼ì´ë” ëì„ ì„¤ì •
    today = date.today()
    today_datetime = datetime.combine(today, datetime.min.time())
    time = st.slider("ë‚ ì§œë¥¼ ì„¤ì •í•˜ì„¸ìš”.", datetime(2021, 1, 1), today_datetime,
                           value=(datetime(2021, 1, 1), today_datetime),
                           format="YYYY/MM/DD")
    
    region_option = st.selectbox("ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”.", 
                          ("ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬ê´‘ì—­ì‹œ", "ì¸ì²œê´‘ì—­ì‹œ", "ê´‘ì£¼ê´‘ì—­ì‹œ",
                           "ëŒ€ì „ê´‘ì—­ì‹œ", "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ê²½ê¸°ë„", "ê°•ì›ë„", 
                           "ì¶©ì²­ë¶ë„", "ì¶©ì²­ë‚¨ë„", "ì „ë¼ë¶ë„", "ì „ë¼ë‚¨ë„", "ê²½ìƒë¶ë„", "ê²½ìƒë‚¨ë„", "ì œì£¼íŠ¹ë³„ìì¹˜ë„"))


    
    
col1, col2 = st.columns([2,2])
with col1:
    st.title("Map")
    map_visualization()

    
with col2:
    st.title("Series")
    # Add code
    flowday = pd.DataFrame()
    timeseries(file_timeseries)

    tab1, tab2, tab3= st.tabs(['Clustering' , 'Wordcloud', 'Histogram'])
    
    with tab1:
        #st.subheader("Clustering")
        clustering(file_clustering)
        
    
    with tab2: 
        #st.subheader("Wordcloud")
        w_cloud()

    with tab3:
        #st.subheader("Histogram")
        histogram()
